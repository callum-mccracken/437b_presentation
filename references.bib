
@unpublished{hartman_4b_2020,
	title = {4B {UPDATE}: {PAIR}-A-{GRAPH}},
	author = {Hartman, Nicole and Kagan, Michael and de Lima, Rafael Teixeira},
	date = {2020-01},
	langid = {english},
	file = {Hartman et al. - 4B UPDATE PAIR-A-GRAPH.pdf:/home/callum/snap/zotero-snap/common/Zotero/storage/MCEKN9CH/Hartman et al. - 4B UPDATE PAIR-A-GRAPH.pdf:application/pdf},
}

@article{atlas_collaboration_measurements_2018,
	title = {Measurements of b-jet tagging efficiency with the {ATLAS} detector using tt¯\$\$ t{\textbackslash}overline\{t\} \$\$events at s=13\$\$ {\textbackslash}sqrt\{s\}=13 \$\${TeV}},
	volume = {2018},
	issn = {1029-8479},
	url = {https://doi.org/10.1007/JHEP08(2018)089},
	doi = {10.1007/JHEP08(2018)089},
	abstract = {The efficiency to identify jets containing b-hadrons (b-jets) is measured using a high purity sample of dileptonic top quark-antiquark pairs (tt¯\$\$ t{\textbackslash}overline\{t\} \$\$) selected from the 36.1 fb−1 of data collected by the {ATLAS} detector in 2015 and 2016 from proton-proton collisions produced by the Large Hadron Collider at a centre-of-mass energy s=13\$\$ {\textbackslash}sqrt\{s\}=13 \$\${TeV}. Two methods are used to extract the efficiency from tt¯\$\$ t{\textbackslash}overline\{t\} \$\$events, a combinatorial likelihood approach and a tag-and-probe method. A boosted decision tree, not using b-tagging information, is used to select events in which two b-jets are present, which reduces the dominant uncertainty in the modelling of the flavour of the jets. The efficiency is extracted for jets in a transverse momentum range from 20 to 300 {GeV}, with data-to-simulation scale factors calculated by comparing the efficiency measured using collision data to that predicted by the simulation. The two methods give compatible results, and achieve a similar level of precision, measuring data-to-simulation scale factors close to unity with uncertainties ranging from 2\% to 12\% depending on the jet transverse momentum.},
	pages = {89},
	number = {8},
	journaltitle = {Journal of High Energy Physics},
	shortjournal = {J. High Energ. Phys.},
	author = {ATLAS Collaboration},
	urldate = {2020-08-23},
	date = {2018-08-16},
	langid = {english},
	file = {Springer Full Text PDF:/home/callum/snap/zotero-snap/common/Zotero/storage/I9NQHE9X/Aaboud et al. - 2018 - Measurements of b-jet tagging efficiency with the .pdf:application/pdf},
}

@article{wattenberg_how_2016,
	title = {How to Use t-{SNE} Effectively},
	volume = {1},
	issn = {2476-0757},
	url = {http://distill.pub/2016/misread-tsne},
	doi = {10.23915/distill.00002},
	abstract = {Although extremely useful for visualizing high-dimensional data, t-{SNE} plots can sometimes be mysterious or misleading.},
	pages = {e2},
	number = {10},
	journaltitle = {Distill},
	shortjournal = {Distill},
	author = {Wattenberg, Martin and Viégas, Fernanda and Johnson, Ian},
	urldate = {2020-08-23},
	date = {2016-10-13},
	langid = {english},
	file = {Snapshot:/home/callum/snap/zotero-snap/common/Zotero/storage/2H99UCN7/Wattenberg et al. - 2016 - How to Use t-SNE Effectively.html:text/html},
}

@online{keitakurita_paper_2018,
	title = {Paper Dissected: “Visualizing Data using t-{SNE}” Explained},
	url = {https://mlexplained.com/2018/09/14/paper-dissected-visualizing-data-using-t-sne-explained/},
	shorttitle = {Paper Dissected},
	abstract = {Visualizing high-dimensional data by projecting it into a low-dimensional space is a classic operation that anyone working with data has probably done at least once in their life. There are a huge …},
	titleaddon = {Machine Learning Explained},
	author = {keitakurita, Author},
	urldate = {2020-08-23},
	date = {2018-09-14},
	langid = {american},
	file = {Snapshot:/home/callum/snap/zotero-snap/common/Zotero/storage/4U97ARTJ/keitakurita - 2018 - Paper Dissected “Visualizing Data using t-SNE” Ex.html:text/html},
}

@inreference{noauthor_b-tagging_2020,
	title = {b-tagging},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {https://en.wikipedia.org/w/index.php?title=B-tagging&oldid=951443640},
	abstract = {b-tagging is a method of jet flavor tagging used in modern particle physics experiments. It is the identification (or "tagging") of jets originating from bottom quarks (or b quarks, hence the name).},
	booktitle = {Wikipedia},
	urldate = {2020-08-23},
	date = {2020-04-17},
	langid = {english},
	note = {Page Version {ID}: 951443640},
	file = {Snapshot:/home/callum/snap/zotero-snap/common/Zotero/storage/XXXEZKJF/2020 - b-tagging.html:text/html},
}

@article{schwartz_tasi_2017,
	title = {{TASI} Lectures on Collider Physics},
	url = {http://arxiv.org/abs/1709.04533},
	abstract = {These lectures provide an introduction to the physics of particle colliders. Topics covered include a quantitative examination of the design and operational parameters of Large Hadron Collider, kinematics and observables at colliders, such as rapidity and transverse mass, and properties of distributions, such as Jacobian peaks. In addition, the lectures provide a practical introduction to the decay modes and signatures of important composite and elementary and particles in the Standard Model, from pions to the Higgs boson. The aim of these lectures is provide a bridge between theoretical and experimental particle physics. Whenever possible, results are derived using intuitive arguments and estimates rather than precision calculations.},
	journaltitle = {{arXiv}:1709.04533 [hep-ph]},
	author = {Schwartz, Matthew D.},
	urldate = {2020-08-23},
	date = {2017-09-13},
	eprinttype = {arxiv},
	eprint = {1709.04533},
	keywords = {High Energy Physics - Phenomenology},
	file = {arXiv Fulltext PDF:/home/callum/snap/zotero-snap/common/Zotero/storage/SQX7VIQI/Schwartz - 2017 - TASI Lectures on Collider Physics.pdf:application/pdf},
}

@article{atlas_collaboration_atlas_2019,
	title = {{ATLAS} \$b\$-jet identification performance and efficiency measurement with \$t{\textbackslash}bar\{t\}\$ events in \$pp\$ collisions at \${\textbackslash}sqrt\{s\}=13\$ {TeV}},
	volume = {79},
	issn = {1434-6044, 1434-6052},
	url = {http://arxiv.org/abs/1907.05120},
	doi = {10.1140/epjc/s10052-019-7450-8},
	abstract = {The algorithms used by the {ATLAS} Collaboration during Run 2 of the Large Hadron Collider to identify jets containing \$b\$-hadrons are presented. The performance of the algorithms is evaluated in the simulation and the efficiency with which these algorithms identify jets containing \$b\$-hadrons is measured in collision data. The measurement uses a likelihood-based method in a sample of highly enriched in \$t{\textbackslash}bar\{t\}\$ events. The topology of the \$t {\textbackslash}to W b\$ decays is exploited to simultaneously measure both the jet flavour composition of the sample and the efficiency in a transverse momentum range from 20 {GeV} to 600 {GeV}. The efficiency measurement is subsequently compared with that predicted by the simulation. The data used in this measurement, corresponding to a total integrated luminosity of 80.5 fb\${\textasciicircum}\{-1\}\$, were collected in proton-proton collisions during the years 2015 to 2017 at a centre-of-mass energy \${\textbackslash}sqrt\{s\}=\$ 13 {TeV}. By simultaneously extracting both the efficiency and jet flavour composition, this measurement significantly improves the precision compared to previous results, with uncertainties ranging from 1\% to 8\% depending on the jet transverse momentum.},
	pages = {970},
	number = {11},
	journaltitle = {The European Physical Journal C},
	shortjournal = {Eur. Phys. J. C},
	author = {{ATLAS Collaboration}},
	urldate = {2020-07-23},
	date = {2019-11},
	eprinttype = {arxiv},
	eprint = {1907.05120},
	keywords = {High Energy Physics - Experiment},
	file = {arXiv Fulltext PDF:/home/callum/snap/zotero-snap/common/Zotero/storage/8HB45DDU/ATLAS Collaboration - 2019 - ATLAS \$b\$-jet identification performance and effic.pdf:application/pdf},
}

@online{the_atlas_collaboration_constraints_2019,
	title = {Constraints on the Higgs boson self-coupling from the combination of single-Higgs and double-Higgs production analyses performed with the {ATLAS} experiment},
	url = {https://cds.cern.ch/record/2693958},
	abstract = {Constraints on the Higgs boson self-coupling are set by combining the single Higgs boson analyses targeting the \${\textbackslash}gamma {\textbackslash}gamma\$, \${ZZ}{\textasciicircum}*\$, \${WW}{\textasciicircum}*\$, \${\textbackslash}tau{\textasciicircum}+ {\textbackslash}tau{\textasciicircum}-\$ and \$b{\textbackslash}bar\{b\}\$ decay channels and the double Higgs boson analyses in the \$b{\textbackslash}bar\{b\}b{\textbackslash}bar\{b\}\$, \$b{\textbackslash}bar\{b\}{\textbackslash}tau{\textasciicircum}+{\textbackslash}tau{\textasciicircum}-\$ and \$b{\textbackslash}bar\{b\} {\textbackslash}gamma {\textbackslash}gamma\$ decay channels, using data collected at \${\textbackslash}sqrt\{s\} = 13\$ {TeV} with the {ATLAS} detector at the {LHC}. The data used in these analyses correspond to an integrated luminosity of up to 79.8 fb\${\textasciicircum}\{-1\}\$ for single Higgs boson analyses and up to 36.1 fb\${\textasciicircum}\{-1\}\$ for the double Higgs boson analyses. With the assumption that new physics affects only the Higgs boson self-coupling (\${\textbackslash}lambda\_\{{HHH}\}\$), values outside the interval \$-2.3\&lt;{\textbackslash}lambda\_\{{HHH}\}/{\textbackslash}lambda\_\{{HHH}\}{\textasciicircum}\{{\textbackslash}textrm\{{SM}\}\}\&lt; 10.3\$ are excluded at 95\% confidence level. Results with less stringent assumptions are also provided, introducing additional coupling modifiers for the Higgs boson interactions with the other Standard Model particles.},
	titleaddon = {{CERN} Document Server},
	author = {The {ATLAS} Collaboration},
	urldate = {2020-07-18},
	date = {2019-10-17},
	langid = {english},
	file = {Full Text PDF:/home/callum/snap/zotero-snap/common/Zotero/storage/VNUZH74W/2019 - Constraints on the Higgs boson self-coupling from .pdf:application/pdf;Snapshot:/home/callum/snap/zotero-snap/common/Zotero/storage/3RBGEFK9/2019 - Constraints on the Higgs boson self-coupling from .html:text/html},
}

@unpublished{seiss_simple_2020,
	title = {Simple Background Model with Neural Net Regression},
	author = {Seiss, Todd},
	date = {2020-07-09},
	langid = {english},
	file = {Seiss - Simple Background Model with Neural Net Regression.pdf:/home/callum/snap/zotero-snap/common/Zotero/storage/Y8CXRAAA/Seiss - Simple Background Model with Neural Net Regression.pdf:application/pdf},
}

@online{lamberta_introduction_nodate,
	title = {Introduction to the Keras Tuner {\textbar} {TensorFlow} Core},
	url = {https://www.tensorflow.org/tutorials/keras/keras_tuner},
	titleaddon = {{TensorFlow}},
	author = {Lamberta, Billy},
	urldate = {2021-01-02},
	langid = {english},
	file = {Snapshot:/home/callum/snap/zotero-snap/common/Zotero/storage/527MZMYU/keras_tuner.html:text/html},
}

@book{kitandidis_introduction_1997,
	title = {Introduction to Geostatistics, Applications in Hydrogeology},
	url = {https://www.cambridge.org/ca/academic/subjects/earth-and-environmental-science/hydrology-hydrogeology-and-water-resources/introduction-geostatistics-applications-hydrogeology, https://www.cambridge.org/ca/academic/subjects/earth-and-environmental-science/hydrology-hydrogeology-and-water-resources},
	author = {Kitandidis, P.K.},
	urldate = {2021-01-02},
	date = {1997-05},
	langid = {english},
	file = {Snapshot:/home/callum/snap/zotero-snap/common/Zotero/storage/7G6W28HT/introduction-geostatistics-applications-hydrogeology.html:text/html},
}

@incollection{cressie_statistics_1993,
	title = {Statistics for Spatial Data},
	rights = {Copyright © 1993 John Wiley \& Sons, Inc.},
	isbn = {978-1-119-11515-1},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9781119115151.ch1},
	abstract = {This chapter contains sections titled: Spatial Data and Spatial Models Introductory Examples Statistics for Spatial Data: Why?},
	booktitle = {Statistics for Spatial Data},
	publisher = {John Wiley \& Sons, Ltd},
	author = {Cressie, Noel A.C.},
	urldate = {2021-01-02},
	date = {1993},
	langid = {english},
	doi = {10.1002/9781119115151.ch1},
	note = {Section: 1
\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781119115151.ch1},
	keywords = {geostatistical data, lattice data, point patterns, spatial data, spatial models},
	file = {Snapshot:/home/callum/snap/zotero-snap/common/Zotero/storage/LEMK4RU4/9781119115151.html:text/html},
}

@software{murphy_geostat-frameworkpykrige_2020,
	title = {{GeoStat}-Framework/{PyKrige} v1.5.1},
	rights = {{BSD} 3-Clause "New" or "Revised" License, Open Access},
	url = {https://zenodo.org/record/3738604},
	abstract = {{\textless}strong{\textgreater}Release Notes {\textless}/strong{\textgreater} {\textless}strong{\textgreater}Installation{\textless}/strong{\textgreater} You can install {PyKrige} with conda: {\textless}pre{\textgreater}{\textless}code{\textgreater}conda install -c conda-forge pykrige {\textless}/code{\textgreater}{\textless}/pre{\textgreater} or with pip: {\textless}pre{\textgreater}{\textless}code{\textgreater}pip install pykrige {\textless}/code{\textgreater}{\textless}/pre{\textgreater} {\textless}strong{\textgreater}Documentation{\textless}/strong{\textgreater} The documentation can be found at: https://pykrige.readthedocs.io/ {\textless}strong{\textgreater}What's new?{\textless}/strong{\textgreater} {\textless}strong{\textgreater}New features{\textless}/strong{\textgreater} update Regression Kriging class to be compatible with all kriging features (\#158) added option to enable/disable "exact values" to all kriging routines (\#153) added option to use the pseudo-inverse in all kriging routines (\#151) {\textless}strong{\textgreater}Changes{\textless}/strong{\textgreater} removed compat-layer for sklearn (\#157) updated examples in documentation},
	version = {v1.5.1},
	publisher = {Zenodo},
	author = {Murphy, Benjamin and Müller, Sebastian and Yurchak, Roman},
	urldate = {2021-01-02},
	date = {2020-08-19},
	doi = {10.5281/ZENODO.3738604},
	note = {Language: en},
	keywords = {external drift kriging, {GeoStat}-Framework, geostatistics, kriging, ordinary kriging, Python, regression kriging, universal kriging, variogram},
}

@article{nielsen_neural_2015,
	title = {Neural Networks and Deep Learning, Chapter 4: A visual proof that neural nets can compute any function},
	url = {http://neuralnetworksanddeeplearning.com/chap4.html},
	author = {Nielsen, Michael A.},
	urldate = {2021-01-02},
	date = {2015},
	langid = {english},
	note = {Publisher: Determination Press},
	file = {Snapshot:/home/callum/snap/zotero-snap/common/Zotero/storage/YPKZMID5/chap4.html:text/html},
}

@article{rezende_variational_2016,
	title = {Variational Inference with Normalizing Flows},
	url = {http://arxiv.org/abs/1505.05770},
	abstract = {The choice of approximate posterior distribution is one of the core problems in variational inference. Most applications of variational inference employ simple families of posterior approximations in order to allow for efficient inference, focusing on mean-field or other simple structured approximations. This restriction has a significant impact on the quality of inferences made using variational methods. We introduce a new approach for specifying flexible, arbitrarily complex and scalable approximate posterior distributions. Our approximations are distributions constructed through a normalizing flow, whereby a simple initial density is transformed into a more complex one by applying a sequence of invertible transformations until a desired level of complexity is attained. We use this view of normalizing flows to develop categories of finite and infinitesimal flows and provide a unified view of approaches for constructing rich posterior approximations. We demonstrate that the theoretical advantages of having posteriors that better match the true posterior, combined with the scalability of amortized variational approaches, provides a clear improvement in performance and applicability of variational inference.},
	journaltitle = {{arXiv}:1505.05770 [cs, stat]},
	author = {Rezende, Danilo Jimenez and Mohamed, Shakir},
	urldate = {2021-01-03},
	date = {2016-06-14},
	eprinttype = {arxiv},
	eprint = {1505.05770},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Computation, Statistics - Machine Learning, Statistics - Methodology},
	file = {arXiv Fulltext PDF:/home/callum/snap/zotero-snap/common/Zotero/storage/MVDYBETA/Rezende and Mohamed - 2016 - Variational Inference with Normalizing Flows.pdf:application/pdf;arXiv.org Snapshot:/home/callum/snap/zotero-snap/common/Zotero/storage/EYRDNDLE/1505.html:text/html},
}

@article{dinh_density_2017,
	title = {Density estimation using Real {NVP}},
	url = {http://arxiv.org/abs/1605.08803},
	abstract = {Unsupervised learning of probabilistic models is a central yet challenging problem in machine learning. Specifically, designing models with tractable learning, sampling, inference and evaluation is crucial in solving this task. We extend the space of such models using real-valued non-volume preserving (real {NVP}) transformations, a set of powerful invertible and learnable transformations, resulting in an unsupervised learning algorithm with exact log-likelihood computation, exact sampling, exact inference of latent variables, and an interpretable latent space. We demonstrate its ability to model natural images on four datasets through sampling, log-likelihood evaluation and latent variable manipulations.},
	journaltitle = {{arXiv}:1605.08803 [cs, stat]},
	author = {Dinh, Laurent and Sohl-Dickstein, Jascha and Bengio, Samy},
	urldate = {2021-01-03},
	date = {2017-02-27},
	eprinttype = {arxiv},
	eprint = {1605.08803},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/home/callum/snap/zotero-snap/common/Zotero/storage/WAL7QLS6/Dinh et al. - 2017 - Density estimation using Real NVP.pdf:application/pdf;arXiv.org Snapshot:/home/callum/snap/zotero-snap/common/Zotero/storage/ZK55CDC7/1605.html:text/html},
}

@software{durkan_nflows_2020,
	title = {\{nflows\}: normalizing flows in \{{PyTorch}\}},
	url = {https://doi.org/10.5281/zenodo.4296287},
	version = {v0.14},
	author = {Durkan, Conor and Bekasov, Artur and Murray, Iain and Papamakarios, George},
	date = {2020-11},
	keywords = {density-estimation, normalizing-flows},
}

@online{hartman_flow-modelsdensityestimatepy_nodate,
	title = {Flow-Models/{densityEstimate}.py · master · Nicole Michelle Hartman / {diHiggs}4b},
	url = {https://gitlab.cern.ch/hartman/dihiggs4b/-/blob/master/Flow-Models/densityEstimate.py},
	abstract = {Exploratory studies for familiarizing myself with the analysis choices and Ntuples for the \$hh{\textbackslash}rightarrow b\$ analysis.},
	titleaddon = {{GitLab}},
	author = {Hartman, Nicole},
	urldate = {2021-01-03},
	langid = {english},
	file = {Snapshot:/home/callum/snap/zotero-snap/common/Zotero/storage/A9V3SKQM/densityEstimate.html:text/html},
}

@online{budde_universal_nodate,
	title = {Universal Kriging : algorithm},
	url = {http://spatial-analyst.net/ILWIS/htm/ilwisapp/universal_kriging_algorithm.htm},
	author = {Budde, Petra and Nijemijer, Raymond},
	urldate = {2021-01-04},
	file = {Universal Kriging \: algorithm:/home/callum/snap/zotero-snap/common/Zotero/storage/WNZZ69RQ/universal_kriging_algorithm.html:text/html},
}

@online{budde_kriging_nodate,
	title = {Kriging : algorithm},
	url = {http://spatial-analyst.net/ILWIS/htm/ilwisapp/kriging_algorithm.htm},
	author = {Budde, Petra and Nijemijer, Raymond},
	urldate = {2021-01-04},
	file = {Kriging \: algorithm:/home/callum/snap/zotero-snap/common/Zotero/storage/YMYZAWD7/kriging_algorithm.html:text/html},
}

@article{the_atlas_collaboration_search_2016,
	title = {Search for pair production of Higgs bosons in the b b ¯ b b ¯ final state using proton-proton collisions at s = 13 {TeV} with the {ATLAS} detector},
	volume = {94},
	issn = {2470-0010, 2470-0029},
	url = {https://link.aps.org/doi/10.1103/PhysRevD.94.052002},
	doi = {10.1103/PhysRevD.94.052002},
	abstract = {A search for Higgs-boson pair production in √the bb¯bb¯ ﬁnal state is carried out with 3.2 fb−1 of proton-proton collision data collected at s = 13 {TeV} with the {ATLAS} detector. The data are consistent with the estimated background and are used to set upper limits on the production cross section times branching ratio to bb¯bb¯ for Kaluza-Klein gravitons in the context of the Randall–Sundrum model with a warped extra dimension and for a simpliﬁed model with a narrow spin-0 resonance. In the context of the Randall–Sundrum model, upper limits of ∼ 70 fb are obtained over a broad mass range of 600 and 3000 {GeV}, at the 95\% conﬁdence level. The production cross section times branching ratio for non-resonant Higgsboson pairs is also constrained to be less than 1.22 pb.},
	pages = {052002},
	number = {5},
	journaltitle = {Physical Review D},
	shortjournal = {Phys. Rev. D},
	author = {ATLAS Collaboration},
	urldate = {2021-01-04},
	date = {2016-09-02},
	langid = {english},
	file = {Aaboud et al. - 2016 - Search for pair production of Higgs bosons in the .pdf:/home/callum/snap/zotero-snap/common/Zotero/storage/YXG8LPBW/Aaboud et al. - 2016 - Search for pair production of Higgs bosons in the .pdf:application/pdf},
}